{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WahoVHqfwSar"
      },
      "outputs": [],
      "source": [
        "# パッケージのクローンとセットアップ\n",
        "!git clone https://github.com/VOICEVOX/voicevox_core -b 0.13.2\n",
        "%cd voicevox_core/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 環境構築\n",
        "\n",
        "# ONNX Runtimeのダウンロード\n",
        "!mkdir onnxruntime\n",
        "!wget https://github.com/microsoft/onnxruntime/releases/download/v1.10.0/onnxruntime-linux-x64-gpu-1.10.0.tgz\n",
        "!tar xf onnxruntime-linux-x64-gpu-1.10.0.tgz -C onnxruntime --strip=1\n",
        "!rm onnxruntime-linux-x64-gpu-1.10.0.tgz\n",
        "# コアライブラリのダウンロード\n",
        "!mkdir release\n",
        "!wget https://github.com/VOICEVOX/voicevox_core/releases/download/0.13.2/voicevox_core-linux-x64-gpu-0.13.2.zip\n",
        "!unzip -qj voicevox_core-linux-x64-gpu-0.13.2.zip -d release\n",
        "!rm voicevox_core-linux-x64-gpu-0.13.2.zip\n",
        "# 配置\n",
        "!mkdir -p core/lib\n",
        "!cp onnxruntime/lib/* core/lib\n",
        "!cp release/* core/lib\n",
        "# 辞書データダウンロード\n",
        "!wget http://downloads.sourceforge.net/open-jtalk/open_jtalk_dic_utf_8-1.11.tar.gz\n",
        "!tar xf open_jtalk_dic_utf_8-1.11.tar.gz\n",
        "!rm open_jtalk_dic_utf_8-1.11.tar.gz"
      ],
      "metadata": {
        "id": "Sp446y6bwU-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqU ."
      ],
      "metadata": {
        "id": "wz2Zpql7wjA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp pytchat numpy sounddevice nest_asyncio openai ipython cohere tiktoken nest_asyncio"
      ],
      "metadata": {
        "id": "h-ptZyCnxUQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import core\n",
        "import asyncio\n",
        "import pytchat\n",
        "import queue\n",
        "import random\n",
        "import openai\n",
        "import IPython.display\n",
        "from IPython.display import display, HTML, Javascript\n",
        "from ipywidgets import widgets\n",
        "from base64 import b64decode\n",
        "from google.colab import output\n",
        "from google.colab import userdata\n",
        "import nest_asyncio\n",
        "import requests"
      ],
      "metadata": {
        "id": "bAVTrGeFxOQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Jj3O9bUXwuFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/AItuber/character.txt'\n",
        "with open(file_path) as f:\n",
        "\tcharacter = f.read()"
      ],
      "metadata": {
        "id": "DtqDOb1YwxV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_character(character):\n",
        "    return [{\"role\": \"system\", \"content\": character}]\n",
        "messages = create_character(character)"
      ],
      "metadata": {
        "id": "TxMsYeYq5O1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import core\n",
        "\n",
        "def initialize_core(use_gpu: bool, cpu_num_threads: int, openjtalk_dict: str):\n",
        "    # コアの初期化\n",
        "    core.initialize(use_gpu, cpu_num_threads)\n",
        "\n",
        "    # openjtalk辞書のロード\n",
        "    core.voicevox_load_openjtalk_dict(openjtalk_dict)\n",
        "\n",
        "initialize_core(use_gpu=True, cpu_num_threads=0, openjtalk_dict=\"open_jtalk_dic_utf_8-1.11\")"
      ],
      "metadata": {
        "id": "EjYwvZqlw101"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tts_and_save(text: str, speaker_id: int):\n",
        "    wavefmt = core.voicevox_tts(text, speaker_id)\n",
        "    if not wavefmt:\n",
        "        return False\n",
        "    try:\n",
        "        with open(\"data.wav\", \"wb\") as f:\n",
        "            f.write(wavefmt)\n",
        "        return True\n",
        "    except IOError as e:\n",
        "        print(f\"ファイル保存時のエラー: {e}\")\n",
        "        return False\n",
        "\n",
        "def text_to_speech(text, speaker_id):\n",
        "    if tts_and_save(text, speaker_id):\n",
        "        file_path = 'data.wav'\n",
        "        display(IPython.display.Audio(file_path, autoplay=True))\n",
        "    else:\n",
        "        print(\"TTSの実行に失敗しました\")\n"
      ],
      "metadata": {
        "id": "gT6XCg6Y1YMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deepl_api_key = userdata.get('DEEPL_API_KEY')\n",
        "\n",
        "def translate_to_english(text):\n",
        "    params = {\n",
        "                \"auth_key\": deepl_api_key,\n",
        "                \"text\": text,\n",
        "                \"source_lang\": 'JA',\n",
        "                \"target_lang\": 'EN'\n",
        "            }\n",
        "    request = requests.post(\"https://api-free.deepl.com/v2/translate\", data=params)\n",
        "    result = request.json()\n",
        "    return result[\"translations\"][0][\"text\"]"
      ],
      "metadata": {
        "id": "NGyVguTpecLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_text_in_frame(text):\n",
        "    # テキストを更新するJavaScriptコード\n",
        "    javascript = f'''\n",
        "    const container = document.getElementById('text-container');\n",
        "    container.innerHTML = `\n",
        "      <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n",
        "      <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n",
        "      <link href=\"https://fonts.googleapis.com/css2?family=Yusei+Magic&display=swap\" rel=\"stylesheet\">\n",
        "      <style>\n",
        "      h1 {{\n",
        "        font-family: 'Yusei Magic', sans-serif;\n",
        "        color: pink;\n",
        "      }}\n",
        "      </style>\n",
        "      <h1>{text}</h1>\n",
        "    `;\n",
        "    '''\n",
        "    display(Javascript(javascript))"
      ],
      "metadata": {
        "id": "egstVZLN2xhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "def fetch_AI_response(messages):\n",
        "    response =  openai.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo-1106\",\n",
        "                    max_tokens=50,\n",
        "                    temperature=0.2,\n",
        "                    messages=messages)\n",
        "    return response\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader();\n",
        "  reader.onloadend = e => resolve(e.srcElement.result);\n",
        "  reader.readAsDataURL(blob);\n",
        "});\n",
        "\n",
        "var recorder, chunks, stream;\n",
        "\n",
        "window.startRecording = async () => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  chunks = [];\n",
        "  recorder.ondataavailable = e => chunks.push(e.data);\n",
        "  recorder.start();\n",
        "};\n",
        "\n",
        "window.stopRecording = () => {\n",
        "  recorder.stop();\n",
        "  stream.getTracks().forEach(track => track.stop());\n",
        "  return new Promise(resolve => {\n",
        "    recorder.onstop = async () => {\n",
        "      blob = new Blob(chunks);\n",
        "      text = await b2text(blob);\n",
        "      resolve(text);\n",
        "    };\n",
        "  });\n",
        "};\n",
        "\"\"\"\n",
        "\n",
        "start_button = widgets.Button(description=\"Start Recording\")\n",
        "stop_button = widgets.Button(description=\"Stop Recording\")\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_start_clicked(b):\n",
        "    output_area.clear_output()\n",
        "    with output_area:\n",
        "        print(\"Recording started...\")\n",
        "    output.eval_js('startRecording()')\n",
        "\n",
        "def on_stop_clicked_sync(b):\n",
        "    asyncio.create_task(on_stop_clicked(b))\n",
        "\n",
        "def on_stop_clicked(b):\n",
        "    with output_area:\n",
        "        print(\"Recording stopped, transcribing...\")\n",
        "        audio_data = output.eval_js('stopRecording()')\n",
        "        transcribed_text = speech_to_text(audio_data)\n",
        "        messages.append({\"role\": \"user\", \"content\": transcribed_text})\n",
        "        response = fetch_AI_response(messages)\n",
        "        if response is not None:\n",
        "                    resp = response.choices[0].message.content.strip()\n",
        "                    print(resp)\n",
        "                    text_to_speech(resp, speaker_id=20)\n",
        "                    text = translate_to_english(resp)\n",
        "                    update_text_in_frame(text)\n",
        "                    messages.append({\"role\": \"assistant\", \"content\": resp})\n",
        "\n",
        "def speech_to_text(audio_data, model='whisper-1', language='ja'):\n",
        "    b = b64decode(audio_data.split(',')[1])\n",
        "\n",
        "    with open('tmp.wav', 'wb') as fw:\n",
        "        fw.write(b)\n",
        "\n",
        "    with open('tmp.wav', \"rb\") as fr:\n",
        "        transcription = openai.audio.transcriptions.create(\n",
        "            model=model,\n",
        "            file=fr,\n",
        "            language=language,\n",
        "            response_format=\"text\"\n",
        "        )\n",
        "        return transcription"
      ],
      "metadata": {
        "id": "EaqYaBdU3TSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments_queue = asyncio.Queue()\n",
        "is_chat_ended = asyncio.Event()\n",
        "\n",
        "async def get_chat(video_id, organizer_name=\"V太郎\", end_message=\"終わり\"):\n",
        "    livechat = pytchat.create(video_id=video_id)\n",
        "    print(f\"ライブチャットを開始しました: {livechat.is_alive()}\")\n",
        "    while livechat.is_alive():\n",
        "        try:\n",
        "            chatdata = await asyncio.to_thread(livechat.get)\n",
        "            if chatdata:\n",
        "                print(f\"取得したチャットデータ: {chatdata.items}\")\n",
        "                for c in chatdata.items:\n",
        "                    print(f\"キューに追加するメッセージ: {c.author.name}: {c.message}\")\n",
        "                    await comments_queue.put(c)\n",
        "                    if c.author.name == organizer_name and c.message == end_message:\n",
        "                        print(\"チャンネル主催者からの終了メッセージが検出されました。プロセスを終了します。\")\n",
        "                        is_chat_ended.set()\n",
        "                        return  # ループを抜け、関数を終了\n",
        "            else:\n",
        "                print(\"取得したチャットデータが空です。\")\n",
        "        except Exception as e:\n",
        "            print(f\"チャットデータの取得中にエラーが発生しました: {e}\")\n",
        "        await asyncio.sleep(5)\n"
      ],
      "metadata": {
        "id": "WaakzHIm5q3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def drain_queue(queue, timeout):\n",
        "    items = []\n",
        "    try:\n",
        "        # キューからアイテムを取得するのを最大 timeout 秒間待機する\n",
        "        while True:\n",
        "            item = await asyncio.wait_for(queue.get(), timeout=timeout)\n",
        "            items.append(item)\n",
        "    except asyncio.TimeoutError:\n",
        "        # タイムアウトが発生したら、これ以上アイテムは待たずに処理を続行\n",
        "        pass\n",
        "    return items\n",
        "\n",
        "async def process_chat_message(queue,messages,keywords):\n",
        "    COMMENT_THRESHOLD = 1  # 閾値を設定（1以上であれば処理を変更）\n",
        "    TIMEOUT = 30  # タイムアウト時間を設定（秒）\n",
        "    while not is_chat_ended.is_set():\n",
        "        comments = await drain_queue(queue, TIMEOUT)\n",
        "        if not comments:\n",
        "            # タイムアウト内にコメントが一つもなかった場合の処理\n",
        "            (\"コメントが一定時間ありませんでした。一人で話して続けて...\")\n",
        "            chat_message = \"コメントがなかったのであなたは新しい話をするか前回話をしていた続きを離します。いきなり話し始めてください\"\n",
        "            # 一人で話す処理をここに追加\n",
        "        elif len(comments) > COMMENT_THRESHOLD:\n",
        "            # コメントが閾値より多い場合の処理\n",
        "            print(f\"多数のコメントがあります: {comments}\")\n",
        "            relevant_comments = [comment for comment in comments if any(keyword in comment.message for keyword in keywords)]\n",
        "            if relevant_comments:\n",
        "                # キーワードに関連するコメントがある場合\n",
        "                chosen_comment = random.choice(relevant_comments)\n",
        "                print(f\"選択された関連するコメント: {chosen_comment.author.name}: {chosen_comment.message}\")\n",
        "            else:\n",
        "                # 関連するコメントがない場合、ランダムに選択\n",
        "                chosen_comment = random.choice(comments)\n",
        "                print(f\"ランダムに選択されたコメント: {chosen_comment.author.name}: {chosen_comment.message}\")\n",
        "            chat_message = chosen_comment\n",
        "        else:\n",
        "            # それ以外（コメントが一つだけある場合）の処理\n",
        "            print(f\"取得したコメント: {comments}\")\n",
        "            # コメントが一つだけの場合の処理をここに追加\n",
        "            messages.append({\"role\": \"user\", \"content\": chat_message})\n",
        "        response = await asyncio.to_thread(\n",
        "        fetch_AI_response,messages)\n",
        "        if response is not None:\n",
        "                resp = response.choices[0].message.content.strip()\n",
        "                print(resp)\n",
        "                update_text_in_frame(resp)\n",
        "                text_to_speech(resp, speaker_id=20)\n",
        "                text = translate_to_english(resp)\n",
        "                messages.append({\"role\": \"assistant\", \"content\": resp})\n",
        "        await asyncio.sleep(TIMEOUT)\n"
      ],
      "metadata": {
        "id": "O5YN_oVN6icB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "display(Javascript(RECORD))\n",
        "async def main():\n",
        "  select_mode = input(\"おしゃべりモード：１, 配信モード：2\")\n",
        "  html_frame = HTML('''\n",
        "  <div id=\"text-container\" style=\"border:1px solid #ccc; padding:10px; width:1000px; height:200px; overflow:auto;\">\n",
        "  ここにテキストが表示されます。\n",
        "  </div>\n",
        "  ''')\n",
        "  display(html_frame)\n",
        "  if select_mode == \"1\":\n",
        "    start_button.on_click(on_start_clicked)\n",
        "    stop_button.on_click(on_stop_clicked)\n",
        "    display(widgets.HBox([start_button, stop_button]), output_area)\n",
        "\n",
        "  if select_mode ==\"2\":\n",
        "    video_id = input(\"video_idを入力して\")\n",
        "    important_words = input(\"重要な単語をカンマ区切りで教えてください\")\n",
        "    collection_of_important_words = important_words.split(\", \")\n",
        "    streaming = await asyncio.gather(\n",
        "        asyncio.create_task(get_chat(video_id)),\n",
        "        asyncio.create_task(process_chat_message(comments_queue,messages,collection_of_important_words))\n",
        "    )\n",
        "\n",
        "asyncio.run(main())\n"
      ],
      "metadata": {
        "id": "9ambEQOX718D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}